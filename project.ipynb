{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8557667-168d-4acb-92a4-c1bb47d9dd5d",
   "metadata": {},
   "source": [
    "# Classifying Suspicious Firms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8795a3-3126-4d6e-878d-c40a37c8431e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Citation of Data\n",
    "Hooda,Nishtha. (2018). Audit Data. UCI Machine Learning Repository. https://doi.org/10.24432/C5930Q."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3a5b-38e3-4417-b838-afbd507b1743",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction \n",
    "\n",
    "Having the need to interact with firms on a daily basis, many people in the world have been victims of fraudulent firms. Although auditors may be able to track a few down, not all can be located. Can we use present and historical risk factors to determine if a firm can be labeled as a fraudulent risk or not?\n",
    "\n",
    "The data, stored as a CSV file, contains one year (2015-2016) exhaustive information on firms that is collected by the Auditor Office of India. The aim of this project is to use this data to develop a model which will help auditors by classifying and finding fraudulent firms. A variety of risk factors are examined in order to reach a score of either 1 (fraudulent) or 0 (not fraudulent) for a firm. There are missing values in the dataset that will be corrected by tidying the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ea4fd-b391-440f-82da-e328a13f4b38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a147e7-c36b-4d64-bd78-401d59d2acf1",
   "metadata": {},
   "source": [
    "First, we load in the packages as well as loading in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b07939-24a8-4d81-9af1-0c0b12b170b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(888)\n",
    "\n",
    "# Loads in the packages\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "install.packages(\"kknn\")\n",
    "library(kknn)\n",
    "\n",
    "\n",
    "# Loads the data into the variable\n",
    "url <- \"https://raw.githubusercontent.com/alexander-zhong/dsci-100-project/main/data/audit_risk.csv\"\n",
    "raw_audit_risk_data <- read_csv(url) \n",
    "\n",
    "head(raw_audit_risk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ec8d9-7b81-4520-a9bf-61000432031d",
   "metadata": {
    "tags": []
   },
   "source": [
    "As we can see from the preview, there is a lot of tidying and cleaning of\n",
    "the data that needs to be done before using it. In addition, from a quick glance of the data, we can recognize that using these variables (inherent risk, detection risk, audit risk, control risk) will be ideal for our classifier since other variables in this dataset do not have a clear definition or meaning/information behind them making it very hard to believe if they are variables to can contribute at all to our classifier. So, lets tidy the data and select the variables we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4c221-bf47-40ad-a248-45d5aa9784a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and turn the Risk variable into a factor for our classification\n",
    "audit_risk_data <- raw_audit_risk_data |>\n",
    "    mutate(Risk = as_factor(Risk)) |>\n",
    "    mutate(Risk = fct_recode(Risk, \"Fraudulent\" = \"1\", \"Not Fraudulent\" = \"0\")) |>\n",
    "    select(Risk, CONTROL_RISK, Inherent_Risk, Audit_Risk) |>\n",
    "    drop_na()\n",
    "    \n",
    "\n",
    "head(audit_risk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37c2ab-241e-4610-bfef-3e6b38efb7f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lets quickly take a look at our data by representing the data with a few \n",
    "tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7fd26-e97d-4dcb-807e-87f4bac612c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see the total number of firms that are considered a risk or not a risk\n",
    "preliminary_table1 <- audit_risk_data |>\n",
    "    group_by(Risk) |>\n",
    "    summarize(Count = n())\n",
    "preliminary_table1\n",
    "\n",
    "\n",
    "# see the average of our predictor variables\n",
    "preliminary_table2 <- audit_risk_data |>\n",
    "    select(CONTROL_RISK, Audit_Risk, Inherent_Risk) |>\n",
    "    map_df(mean, na.rm = TRUE)\n",
    "\n",
    "preliminary_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f0603-4eaf-43d1-af21-e824dbca494b",
   "metadata": {},
   "source": [
    "The amount of fraudulent firms is way greater than we expected! Lets take look at the scatter plot distribution of our data with the variables we decided to use. Lets also standardize the data first so we can have a more accurate comparison between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff9206-ffcd-487a-ac7d-07a3cbbcebc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "options(jupyter.plot_mimetypes = c(\"text/plain\", \"image/png\" ))\n",
    "\n",
    "preliminary_plot1 <- audit_risk_data |> \n",
    "    ggplot(aes(x = Inherent_Risk, y = Audit_Risk, color = Risk)) +\n",
    "    geom_point(alpha = 0.4) + \n",
    "    labs(x = \"Inherent Risk (Unstandardized)\", y = \"Audit Risk (Unstandardized)\") +\n",
    "    ggtitle(\"Inherent Risk against Audit Risk\") +\n",
    "    scale_x_log10(labels = label_comma()) +\n",
    "    ylim(0, 10) +\n",
    "    ggtitle(\"Inherent Risk against Audit Risk (Scaled with Log base of 10)\")\n",
    "\n",
    "preliminary_plot1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Standardizing the data\n",
    "audit_recipe <- recipe(Risk ~ CONTROL_RISK + Audit_Risk + Inherent_Risk, data = audit_risk_data) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    prep()\n",
    "\n",
    "audit_risk_scaled <- bake(audit_recipe, audit_risk_data)\n",
    "\n",
    "head(audit_risk_scaled)\n",
    "\n",
    "preliminary_plot2 <- audit_risk_scaled |> \n",
    "    ggplot(aes(x = Inherent_Risk, y = Audit_Risk, color = Risk)) +\n",
    "    geom_point(alpha = 0.2) + \n",
    "    labs(x = \"Inherent Risk (Standardized)\", y = \"Audit Risk (Standardized)\") +\n",
    "    ggtitle(\"Standardized Inherent Risk against Audit Risk\") +\n",
    "    xlim(-0.45, 0.45) +\n",
    "    ylim(-0.25, 0)\n",
    "    \n",
    "preliminary_plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2900f-be8d-4bb3-add5-7cfdceeaf863",
   "metadata": {},
   "source": [
    "From all our visualization and tables, we can conclude that the three variables (control risk, inherent risk, and audit risk) can be used to train our classifier. As we can see, there is a clear upward trend in the scatter plots of Audit Risk vs Inherent Risk leading to more fraudulent firms which further supports our decision in using these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e865e5-7bd1-4f1f-88af-885239ff507b",
   "metadata": {},
   "source": [
    "## Building Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3d50b-9459-4d73-a88f-8ed54791d337",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2654a24-2879-43b1-946c-03f79a6d1c84",
   "metadata": {},
   "source": [
    "This classifier will be based on the K-Nearest Neighbors algorithm to determine\n",
    "whether a firm is considered fraudulent or not. In order to do so, tune and evaluate the classifier for the most optimal K value and testing the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620e623-757c-4af6-afc2-9f1792c72768",
   "metadata": {},
   "source": [
    "First, lets scale the data as well as split the data randomly with set.seed(888) in code cells above for a 70% training data and a 30% testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18f26c-5e4a-4c96-b43c-7068d4063fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "\n",
    "audit_risk_split <- initial_split(audit_risk_data, prop = .7, strata = Risk)\n",
    "audit_risk_train <- training(audit_risk_split)\n",
    "audit_risk_test <- testing(audit_risk_split)\n",
    "\n",
    "audit_recipe <- recipe(Risk ~ CONTROL_RISK + Audit_Risk + Inherent_Risk, data = audit_risk_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991de58d-16c6-4801-8a11-f974c6515251",
   "metadata": {},
   "source": [
    "Now, we want to use cross validation within our training data to choose the correct k-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630ada8-4f8b-40db-a837-ed9c6a14e996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "\n",
    "audit_vfold <- vfold_cv(audit_risk_train, v = 5, strata = Risk) \n",
    "\n",
    "\n",
    "knn_spec <- nearest_neighbor(\n",
    "    weight_func = \"rectangular\", \n",
    "    neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "    add_recipe(audit_recipe) |>\n",
    "    add_model(knn_spec) |>\n",
    "    tune_grid(resamples = audit_vfold, grid = 10) |>\n",
    "    collect_metrics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db054ef-0ad9-4892-a9db-12434cb25e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "\n",
    "accuracies <- knn_results |> \n",
    "       filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = \"K Value\", y = \"Accuracy Estimate\") +\n",
    "    scale_x_continuous(breaks = seq(0, 14, by = 1)) \n",
    "accuracy_versus_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bbb43-3248-4ad2-85b8-3738882373c1",
   "metadata": {},
   "source": [
    "As we can see from our tuning, the value 4 would provide a very high accuracy. But, as we increase the k value from 4, there is a dramatic drop. In our case, we should built our classifier with the k-value of 4 to maximize accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e5f26-4b66-43ce-8979-f9c5cbba111a",
   "metadata": {},
   "source": [
    "### Constructing the Classifier with K Value of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0ddb4-b78b-423b-bbc1-c653a033bffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audit_recipe <- recipe(Risk ~ CONTROL_RISK + Audit_Risk + Inherent_Risk, data = audit_risk_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 4) |>\n",
    "       set_engine(\"kknn\") |>\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "\n",
    "audit_fit <- workflow() |>\n",
    "    add_recipe(audit_recipe) |>\n",
    "    add_model(knn_spec) |>\n",
    "    fit(data = audit_risk_train)\n",
    "\n",
    "audit_predictions <- predict(audit_fit, audit_risk_test) |>\n",
    "    bind_cols(audit_risk_test)\n",
    "\n",
    "head(audit_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca3531-c099-4d4a-b25d-bc4543caed50",
   "metadata": {},
   "source": [
    "Now that we have used our training data to creat our classifier and used it to predict the training data, we can take a look at the metrics to see how well our classifier did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd462e9-833a-40ab-80e2-90f4b74f44f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audit_prediction_metrics <- audit_predictions |>\n",
    "    metrics(truth = Risk, estimate = .pred_class)\n",
    "\n",
    "\n",
    "audit_prediction_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722057f9-0aee-45a9-b635-7340ed0fbf72",
   "metadata": {
    "tags": []
   },
   "source": [
    "As we can see here, our accuracy of our classifier is pretty high with\n",
    "0.9957265 success rate when classifying our testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80808cd-cd73-40a7-af9a-ca50043e884f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discussion\n",
    "- summarize what you found\n",
    "- discuss whether this is what you expected to find?\n",
    "- discuss what impact could such findings have?\n",
    "- discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d132734-b2f7-41cc-b419-6f85f5c7151a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
